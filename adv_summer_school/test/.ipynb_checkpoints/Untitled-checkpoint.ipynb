{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "import torch.utils.data as Data\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from IPython import display\n",
    "import matplotlib.pylab as plt\n",
    "import ipywidgets\n",
    "import glob\n",
    "import os\n",
    "import PIL.Image as Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download if necessary\n",
    "train_set = datasets.MNIST('./data',train=True,download=True,transform=transforms.ToTensor())\n",
    "test_set = datasets.MNIST('./data',train=False,download=True,transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_mnist(data_set):\n",
    "    data_set_c = np.zeros([len(data_set),28,28,3],dtype=np.float32)\n",
    "    lbs = np.zeros([len(data_set),1],dtype=np.float64)\n",
    "    for idx, (x, y) in zip(range(len(data_set)),data_set):\n",
    "        x = x.numpy().transpose(1,2,0).reshape(28,28,1)\n",
    "        # colorize\n",
    "        xr = np.zeros_like(x)\n",
    "        xb = np.zeros_like(x)\n",
    "        xg = np.zeros_like(x)\n",
    "        # threshold\n",
    "        xbin = x > 0.5\n",
    "        xr[xbin]=cmap[y,0]\n",
    "        xb[xbin]=cmap[y,1]\n",
    "        xg[xbin]=cmap[y,2]\n",
    "        xc = np.concatenate([xr,xg,xb],axis=2)\n",
    "        data_set_c[idx,:]=xc\n",
    "        lbs[idx] = y\n",
    "    return data_set_c, lbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "cmap = np.array([[0, 0, 2/3],\n",
    "        [0, 0, 1],\n",
    "        [0, 1/3, 1],\n",
    "        [0, 2/3, 1],\n",
    "        [0, 1, 1],\n",
    "        [1/3,1,2/3],\n",
    "        [2/3,1,1/3],\n",
    "        [1,1,0],\n",
    "        [1,2/3,0],\n",
    "        [1,1/3,0]])\n",
    "\n",
    "biased_train_set, train_labels = color_mnist(train_set)\n",
    "biased_test_set, test_labels = color_mnist(test_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 3, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "biased_train_set = biased_train_set.swapaxes(3,1)\n",
    "print(biased_train_set.shape)\n",
    "torch_dataset = Data.TensorDataset(torch.tensor(biased_train_set), torch.tensor(train_labels))\n",
    "\n",
    "train_loader = DataLoader(torch_dataset, batch_size=batch_size, shuffle=True, num_workers=3)\n",
    "#test_loader = DataLoader(list(zip(np.rollaxis(biased_test_set, 3, 1), test_labels)), batch_size=batch_size, shuffle=False, num_workers=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show some image\n",
    "images, labels = next(iter(train_loader))\n",
    "print(labels.dtype)\n",
    "plt.figure(figsize=(20,10))\n",
    "label_name = ['0','1','2','3','4','5','6','7','8','9']\n",
    "for i in range(16):\n",
    "    plt.subplot(4,4,i+1)\n",
    "    plt.imshow(np.swapaxes(images[i].numpy(), 0, 2))\n",
    "    #print(labels[i].item())\n",
    "    plt.title(label_name[int(labels[i].item())])\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The code will run on CPU. You should probably not do this.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"The code will run on GPU. This is important so things run faster.\")\n",
    "else:\n",
    "    print(\"The code will run on CPU. You should probably not do this.\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN_G(nn.Module):\n",
    "    def __init__(self, input_features, output_features):\n",
    "        super(GAN_G, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.ConvTranspose2d(input_features, 512, 3, stride=2), # 1->3\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ConvTranspose2d(512, 256, 3, stride=2),# 3->7\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ConvTranspose2d(256, 128, 2, stride=2),# 7->14\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ConvTranspose2d(128, 64, 2, stride=2),# 14->28\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(64, output_features, 3, stride=1, padding = 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), x.size(1), 1, 1)\n",
    "#         print(x.shape)\n",
    "        x = self.fc(x)\n",
    "#         x = x.view(x.size(0), 1, 28, 28)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN_D(nn.Module):\n",
    "    def __init__(self, input_features, output_features):\n",
    "        super(GAN_D, self).__init__()   \n",
    "        self.cnn0 = nn.Sequential(\n",
    "            nn.Conv2d(3, 128, 3, stride = 2, padding = 1), # 28 -> 14\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Dropout(p=0.5)\n",
    "#             nn.BatchNorm2d(128),\n",
    "        )\n",
    "        \n",
    "        self.cnn1 = nn.Sequential(\n",
    "            nn.Conv2d(128,256,3, stride = 2, padding = 1), # 14-> 7\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Dropout(p=0.5)\n",
    "#             nn.BatchNorm2d(256)\n",
    "        )\n",
    "        \n",
    "        self.cnn2 = nn.Sequential(\n",
    "            nn.Conv2d(256,512,7, stride = 1, padding = 0), # 7 -> 1\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Dropout(p=0.5)\n",
    "#             nn.BatchNorm2d(512)\n",
    "        )\n",
    "        \n",
    "        self.discriminator = nn.Sequential(\n",
    "            nn.Conv2d(512,output_features,1, stride = 1, padding = 0), # 1 -> 1\n",
    "#             nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.cnn0(x)\n",
    "        x = self.cnn1(x)\n",
    "        x = self.cnn2(x)\n",
    "        x = self.discriminator(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.BCELoss()\n",
    "def cgan_loss_d(d_real, x_label, d_xhat, z_label):\n",
    "    ## use soft-max\n",
    "    d_real = torch.sigmoid(d_real)\n",
    "    d_xhat = torch.sigmoid(d_xhat)\n",
    "    return loss(d_real,x_label)+loss(d_xhat,z_label)\n",
    "    \n",
    "\n",
    "def cgan_loss_g(d_xhat, z_label):\n",
    "    d_xhat = torch.sigmoid(d_xhat)\n",
    "    return loss(d_xhat,z_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize networks\n",
    "d = GAN_D(3,10).to(device)\n",
    "g = GAN_G(110,3).to(device)\n",
    "d_opt = torch.optim.Adam(d.parameters(), 0.0002, (0.5, 0.999))\n",
    "g_opt = torch.optim.Adam(g.parameters(), 0.0001, (0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-45-58cdf57e1a5f>, line 52)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-45-58cdf57e1a5f>\"\u001b[1;36m, line \u001b[1;32m52\u001b[0m\n\u001b[1;33m    img = np.swapaxes(xhat_k.numpy(), 0, 2))\u001b[0m\n\u001b[1;37m                                           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "visualization = ipywidgets.Output()\n",
    "display.display(visualization)\n",
    "\n",
    "with visualization:\n",
    "    plt.figure(figsize=(20,10))\n",
    "subplots = [plt.subplot(2, 6, k+1) for k in range(12)]\n",
    "num_epochs = 10\n",
    "for epoch in tqdm(range(num_epochs), unit='epoch'):\n",
    "    for minibatch_no, (x, target) in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "        label_cpu = torch.zeros((x.shape[0],10))\n",
    "#         print(target.numpy())\n",
    "        label_cpu[np.arange(x.shape[0]),target.numpy()] = 1\n",
    "        x = x.to(device)*2-1\n",
    "        x_label = label_cpu.to(device)\n",
    "#         print(x.shape)\n",
    "        d_real = d(x)\n",
    "        \n",
    "        #Update Discriminator\n",
    "        z = torch.randn(x.shape[0], 100)\n",
    "        z_label = torch.zeros((z.shape[0],10))\n",
    "        random_id = torch.randint(0,10,(z.shape[0],))\n",
    "        z_label_gen = torch.zeros((z.shape[0],10))\n",
    "        z_label_gen[np.arange(x.shape[0]),random_id.numpy()]=1\n",
    "#         print(z_label_gen)\n",
    "        z_combine = torch.cat((z,z_label_gen),dim=1)\n",
    "#         print(z_combine.shape)\n",
    "        z_combine = z_combine.to(device)\n",
    "        z_label = z_label.to(device)\n",
    "        d.zero_grad()\n",
    "        with torch.no_grad(): #We don't need gradients for G when we update D\n",
    "            xhat = g(z_combine)\n",
    "        d_loss=cgan_loss_d(d_real, x_label, d(xhat), z_label)\n",
    "        d_loss.backward()\n",
    "        d_opt.step()\n",
    "\n",
    "        #Update Generator\n",
    "        z = torch.randn(x.shape[0], 100)\n",
    "        z = torch.cat((z,label_cpu),dim=1)\n",
    "        z = z.to(device)\n",
    "        g.zero_grad()\n",
    "        xhat = g(z)\n",
    "        g_loss = cgan_loss_g(d(xhat), x_label)\n",
    "        g_loss.backward()\n",
    "        g_opt.step()\n",
    "        \n",
    "        assert(not np.isnan(d_loss.item()))\n",
    "        #Plot every 100 minibatches\n",
    "        if minibatch_no % 100 == 0:\n",
    "            with torch.no_grad(), visualization:\n",
    "                for k in range(11):\n",
    "                    xhat_k = xhat[k].cpu().squeeze()/2+.5\n",
    "                    img = np.swapaxes(xhat_k.numpy(), 0, 2)\n",
    "                    subplots[k].imshow(img)\n",
    "                    subplots[k].set_title('Label=%d' % target[k])\n",
    "                    subplots[k].axis('off')\n",
    "                    zsample = torch.randn(batch_size, 100)\n",
    "                    zsample = torch.cat((zsample,label_cpu),dim=1)\n",
    "                    zsample = zsample.to(device)\n",
    "                    H1 = d(g(zsample))\n",
    "                    H2 = d(x)\n",
    "\n",
    "                    subplots[11].cla()\n",
    "                    subplots[11].hist(H1.cpu().squeeze(), label='fake', range=(0, 1), alpha=0.5)\n",
    "                    subplots[11].hist(H2.cpu().squeeze(), label='real', range=(0, 1), alpha=0.5)\n",
    "                    subplots[11].legend()\n",
    "                    subplots[11].set_title('Discriminator loss: %.2f' % d_loss.item())\n",
    "\n",
    "                    display.display(plt.gcf())\n",
    "                    display.clear_output(wait=True)\n",
    "        \n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
