{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zfxGXo193zVM"
   },
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import numpy as np\n",
    "from random import seed, shuffle\n",
    "SEED = 1122334455\n",
    "seed(SEED) # set the random seed so that the random permutations can be reproduced again\n",
    "np.random.seed(SEED)\n",
    "import os,sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 24173,
     "status": "ok",
     "timestamp": 1568154643837,
     "user": {
      "displayName": "Hu Xiao",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCYEuPXFTMSisFgiWhSqUJvzs0MjakNcUO3hyguzQ=s64",
      "userId": "02825967592979012764"
     },
     "user_tz": -120
    },
    "id": "35KcmPyJ47lV",
    "outputId": "99ac4fc5-714e-40f1-dd72-f73cf1490c9d"
   },
   "outputs": [],
   "source": [
    "# if use colab\n",
    "\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/gdrive')\n",
    "#!ls /content/gdrive/My\\ Drive/Colab\\ Notebooks/fair-classification-master/fair-classification-master/fair_classification\n",
    "#sys.path.append('/content/gdrive/My Drive/Colab Notebooks/fair-classification-master/fair-classification-master/fair_classification')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6214,
     "status": "ok",
     "timestamp": 1568154651859,
     "user": {
      "displayName": "Hu Xiao",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCYEuPXFTMSisFgiWhSqUJvzs0MjakNcUO3hyguzQ=s64",
      "userId": "02825967592979012764"
     },
     "user_tz": -120
    },
    "id": "ELGZtblj5EaX",
    "outputId": "e9d2f87a-80a8-4315-acfd-09b7817278c6"
   },
   "outputs": [],
   "source": [
    "thirdparty='./fair-classification-master/fair-classification-master/fair_classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XUqmSuMF3zVQ"
   },
   "outputs": [],
   "source": [
    "sys.path.insert(0,thirdparty)\n",
    "import utils as ut\n",
    "import loss_funcs as lf # loss funcs that can be optimized subject to various constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vWIano_a3zVS"
   },
   "outputs": [],
   "source": [
    "def load_adult_data(filepath, load_data_size=None):\n",
    "\n",
    "    \"\"\"\n",
    "        if load_data_size is set to None (or if no argument is provided), then we load and return the whole data\n",
    "        if it is a number, say 10000, then we will return randomly selected 10K examples\n",
    "    \"\"\"\n",
    "\n",
    "    attrs = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', \n",
    "             'occupation', 'relationship', 'race', 'sex', 'capital_gain', 'capital_loss', \n",
    "             'hours_per_week', 'native_country'] # all attributes\n",
    "    int_attrs = ['age', 'fnlwgt', 'education_num', 'capital_gain', 'capital_loss', 'hours_per_week'] # attributes with integer values -- the rest are categorical\n",
    "    sensitive_attrs = ['sex'] # the fairness constraints will be used for this feature\n",
    "    attrs_to_ignore = ['sex', 'race' ,'fnlwgt'] # sex and race are sensitive feature so we will not use them in classification, we will not consider fnlwght for classification since its computed externally and it highly predictive for the class (for details, see documentation of the adult data)\n",
    "    attrs_for_classification = set(attrs) - set(attrs_to_ignore)\n",
    "\n",
    "    # adult data comes in two different files, one for training and one for testing, however, we will combine data from both the files\n",
    "    data_files = [filepath+\"/adult.data\", filepath+\"/adult.test\"]\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "    x_control = {}\n",
    "\n",
    "    attrs_to_vals = {} # will store the values for each attribute for all users\n",
    "    for k in attrs:\n",
    "        if k in sensitive_attrs:\n",
    "            x_control[k] = []\n",
    "        elif k in attrs_to_ignore:\n",
    "            pass\n",
    "        else:\n",
    "            attrs_to_vals[k] = []\n",
    "\n",
    "    for f in data_files:\n",
    "        for line in open(f):\n",
    "            line = line.strip()\n",
    "            if line == \"\": continue # skip empty lines\n",
    "            line = line.split(\", \")\n",
    "            if len(line) != 15 or \"?\" in line: # if a line has missing attributes, ignore it\n",
    "                continue\n",
    "\n",
    "            class_label = line[-1]\n",
    "            if class_label in [\"<=50K.\", \"<=50K\"]:\n",
    "                class_label = -1\n",
    "            elif class_label in [\">50K.\", \">50K\"]:\n",
    "                class_label = +1\n",
    "            else:\n",
    "                raise Exception(\"Invalid class label value\")\n",
    "\n",
    "            y.append(class_label)\n",
    "\n",
    "\n",
    "            for i in range(0,len(line)-1):\n",
    "                attr_name = attrs[i]\n",
    "                attr_val = line[i]\n",
    "                # reducing dimensionality of some very sparse features\n",
    "                if attr_name == \"native_country\":\n",
    "                    if attr_val!=\"United-States\":\n",
    "                        attr_val = \"Non-United-Stated\"\n",
    "                elif attr_name == \"education\":\n",
    "                    if attr_val in [\"Preschool\", \"1st-4th\", \"5th-6th\", \"7th-8th\"]:\n",
    "                        attr_val = \"prim-middle-school\"\n",
    "                    elif attr_val in [\"9th\", \"10th\", \"11th\", \"12th\"]:\n",
    "                        attr_val = \"high-school\"\n",
    "\n",
    "                if attr_name in sensitive_attrs:\n",
    "                    x_control[attr_name].append(attr_val)\n",
    "                elif attr_name in attrs_to_ignore:\n",
    "                    pass\n",
    "                else:\n",
    "                    attrs_to_vals[attr_name].append(attr_val)\n",
    "\n",
    "    def convert_attrs_to_ints(d): # discretize the string attributes\n",
    "        for attr_name, attr_vals in d.items():\n",
    "            if attr_name in int_attrs: continue\n",
    "            uniq_vals = sorted(list(set(attr_vals))) # get unique values\n",
    "\n",
    "            # compute integer codes for the unique values\n",
    "            val_dict = {}\n",
    "            for i in range(0,len(uniq_vals)):\n",
    "                val_dict[uniq_vals[i]] = i\n",
    "\n",
    "            # replace the values with their integer encoding\n",
    "            for i in range(0,len(attr_vals)):\n",
    "                attr_vals[i] = val_dict[attr_vals[i]]\n",
    "            d[attr_name] = attr_vals\n",
    "\n",
    "    \n",
    "    # convert the discrete values to their integer representations\n",
    "    convert_attrs_to_ints(x_control)\n",
    "    convert_attrs_to_ints(attrs_to_vals)\n",
    "\n",
    "\n",
    "    # if the integer vals are not binary, we need to get one-hot encoding for them\n",
    "    for attr_name in attrs_for_classification:\n",
    "        attr_vals = attrs_to_vals[attr_name]\n",
    "        if attr_name in int_attrs or attr_name == \"native_country\": # the way we encoded native country, its binary now so no need to apply one hot encoding on it\n",
    "            X.append(attr_vals)\n",
    "\n",
    "        else:            \n",
    "            attr_vals, index_dict = ut.get_one_hot_encoding(attr_vals)\n",
    "            for inner_col in attr_vals.T:                \n",
    "                X.append(inner_col) \n",
    "\n",
    "\n",
    "    # convert to numpy arrays for easy handline\n",
    "    X = np.array(X, dtype=float).T\n",
    "    y = np.array(y, dtype = float)\n",
    "    for k, v in x_control.items(): x_control[k] = np.array(v, dtype=float)\n",
    "        \n",
    "    # shuffle the data\n",
    "    perm = [i for i in range(len(y))]#range(0,len(y)) # shuffle the data before creating each fold\n",
    "    shuffle(perm)\n",
    "    X = X[perm]\n",
    "    y = y[perm]\n",
    "    for k in x_control.keys():\n",
    "        x_control[k] = x_control[k][perm]\n",
    "\n",
    "    # see if we need to subsample the data\n",
    "    if load_data_size is not None:\n",
    "        #print \"Loading only %d examples from the data\" % load_data_size\n",
    "        X = X[:load_data_size]\n",
    "        y = y[:load_data_size]\n",
    "        for k in x_control.keys():\n",
    "            x_control[k] = x_control[k][:load_data_size]\n",
    "\n",
    "    return X, y, x_control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hnqMWHbF3zVW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qN_q8nQG3zVZ"
   },
   "outputs": [],
   "source": [
    "def test_adult_data(filepath='./data'):\n",
    "    \"\"\" Load the adult data \"\"\"\n",
    "    #X, y, x_control = load_adult_data('/content/gdrive/My Drive/Colab Notebooks',load_data_size=10000)#load_adult_data(load_data_size=10000) # set the argument to none, or no arguments if you want to test with the whole data -- we are subsampling for performance speedup\n",
    "    X, y, x_control = load_adult_data(filepath,load_data_size=10000)#load_adult_data(load_data_size=10000) # set the argument to none, or no arguments if you want to test with the whole data -- we are subsampling for performance speedup\n",
    "    ut.compute_p_rule(x_control[\"sex\"], y) # compute the p-rule in the original data\n",
    "\n",
    "    \"\"\" Split the data into train and test \"\"\"\n",
    "    X = ut.add_intercept(X) # add intercept to X before applying the linear classifier\n",
    "    train_fold_size = 0.7\n",
    "    x_train, y_train, x_control_train, x_test, y_test, x_control_test = ut.split_into_train_test(X, y, x_control, train_fold_size)\n",
    "\n",
    "    apply_fairness_constraints = None\n",
    "    apply_accuracy_constraint = None\n",
    "    sep_constraint = None\n",
    "\n",
    "    loss_function = lf._logistic_loss\n",
    "    sensitive_attrs = [\"sex\"]\n",
    "    sensitive_attrs_to_cov_thresh = {}\n",
    "    gamma = None\n",
    "\n",
    "    def train_test_classifier():\n",
    "        w = ut.train_model(x_train, y_train, x_control_train, loss_function, \n",
    "                           apply_fairness_constraints, apply_accuracy_constraint, \n",
    "                           sep_constraint, sensitive_attrs, \n",
    "                           sensitive_attrs_to_cov_thresh, gamma)\n",
    "        train_score, test_score, correct_answers_train, correct_answers_test = ut.check_accuracy(w, x_train, y_train, x_test, y_test, None, None)\n",
    "        distances_boundary_test = (np.dot(x_test, w)).tolist()\n",
    "        all_class_labels_assigned_test = np.sign(distances_boundary_test)\n",
    "        correlation_dict_test = ut.get_correlations(None, None, all_class_labels_assigned_test, x_control_test, sensitive_attrs)\n",
    "        cov_dict_test = ut.print_covariance_sensitive_attrs(None, x_test, distances_boundary_test, x_control_test, sensitive_attrs)\n",
    "        p_rule = ut.print_classifier_fairness_stats([test_score], [correlation_dict_test], [cov_dict_test], sensitive_attrs[0])\t\n",
    "        return w, p_rule, test_score\n",
    "\n",
    "\n",
    "    \"\"\" Classify the data while optimizing for accuracy \"\"\"\n",
    "    print\n",
    "    print(\"== Unconstrained (original) classifier ==\")\n",
    "    # all constraint flags are set to 0 since we want to train an unconstrained (original) classifier\n",
    "    apply_fairness_constraints = 0\n",
    "    apply_accuracy_constraint = 0\n",
    "    sep_constraint = 0\n",
    "    w_uncons, p_uncons, acc_uncons = train_test_classifier()\n",
    "\n",
    "    \"\"\" Now classify such that we optimize for accuracy while achieving perfect fairness \"\"\"\n",
    "    apply_fairness_constraints = 1 # set this flag to one since we want to optimize accuracy subject to fairness constraints\n",
    "    apply_accuracy_constraint = 0\n",
    "    sep_constraint = 0\n",
    "    sensitive_attrs_to_cov_thresh = {\"sex\":0}\n",
    "    print\n",
    "    print(\"== Classifier with fairness constraint ==\")\n",
    "    w_f_cons, p_f_cons, acc_f_cons  = train_test_classifier()\n",
    "\n",
    "    \"\"\" Classify such that we optimize for fairness subject to a certain loss in accuracy \"\"\"\n",
    "    apply_fairness_constraints = 0 # flag for fairness constraint is set back to0 since we want to apply the accuracy constraint now\n",
    "    apply_accuracy_constraint = 1 # now, we want to optimize fairness subject to accuracy constraints\n",
    "    sep_constraint = 0\n",
    "    gamma = 0.5 # gamma controls how much loss in accuracy we are willing to incur to achieve fairness -- increase gamme to allow more loss in accuracy\n",
    "    print(\"== Classifier with accuracy constraint ==\")\n",
    "    w_a_cons, p_a_cons, acc_a_cons = train_test_classifier()\t\n",
    "\n",
    "    \"\"\" \n",
    "    Classify such that we optimize for fairness subject to a certain loss in accuracy \n",
    "    In addition, make sure that no points classified as positive by the unconstrained (original) classifier are misclassified.\n",
    "\n",
    "    \"\"\"\n",
    "    apply_fairness_constraints = 0 # flag for fairness constraint is set back to0 since we want to apply the accuracy constraint now\n",
    "    apply_accuracy_constraint = 1 # now, we want to optimize accuracy subject to fairness constraints\n",
    "    sep_constraint = 1 # set the separate constraint flag to one, since in addition to accuracy constrains, we also want no misclassifications for certain points (details in demo README.md)\n",
    "    gamma = 1000.0\n",
    "    print(\"== Classifier with accuracy constraint (no +ve misclassification) ==\")\n",
    "    w_a_cons_fine, p_a_cons_fine, acc_a_cons_fine  = train_test_classifier()\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 127965,
     "status": "ok",
     "timestamp": 1568154795840,
     "user": {
      "displayName": "Hu Xiao",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCYEuPXFTMSisFgiWhSqUJvzs0MjakNcUO3hyguzQ=s64",
      "userId": "02825967592979012764"
     },
     "user_tz": -120
    },
    "id": "okLM3V2w3zVc",
    "outputId": "ede0b4f6-89ee-40c4-ebc8-fa29b9e7093f"
   },
   "outputs": [],
   "source": [
    "test_adult_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9VemQHyY3zVg"
   },
   "outputs": [],
   "source": [
    "def test_adult_data_max_acc_under_fairness_constraints(crange,filepath='./data'):\n",
    "    \"\"\" Load the adult data \"\"\"\n",
    "    X, y, x_control = load_adult_data(filepath,load_data_size=30000) # set the argument to none, or no arguments if you want to test with the whole data -- we are subsampling for performance speedup\n",
    "    ut.compute_p_rule(x_control[\"sex\"], y) # compute the p-rule in the original data\n",
    "\n",
    "    \"\"\" Split the data into train and test \"\"\"\n",
    "    X = ut.add_intercept(X) # add intercept to X before applying the linear classifier\n",
    "    train_fold_size = 0.7\n",
    "    x_train, y_train, x_control_train, x_test, y_test, x_control_test = ut.split_into_train_test(X, y, x_control, train_fold_size)\n",
    "\n",
    "    apply_fairness_constraints = None\n",
    "    apply_accuracy_constraint = None\n",
    "    sep_constraint = None\n",
    "\n",
    "    loss_function = lf._logistic_loss\n",
    "    sensitive_attrs = [\"sex\"]\n",
    "    sensitive_attrs_to_cov_thresh = {}\n",
    "    gamma = None\n",
    "\n",
    "    def train_test_classifier():\n",
    "        w = ut.train_model(x_train, y_train, x_control_train, loss_function, \n",
    "                           apply_fairness_constraints, apply_accuracy_constraint, \n",
    "                           sep_constraint, sensitive_attrs, \n",
    "                           sensitive_attrs_to_cov_thresh, gamma)\n",
    "        train_score, test_score, correct_answers_train, correct_answers_test = ut.check_accuracy(w, x_train, y_train, x_test, y_test, None, None)\n",
    "        distances_boundary_test = (np.dot(x_test, w)).tolist()\n",
    "        all_class_labels_assigned_test = np.sign(distances_boundary_test)\n",
    "        correlation_dict_test = ut.get_correlations(None, None, all_class_labels_assigned_test, x_control_test, sensitive_attrs)\n",
    "        cov_dict_test = ut.print_covariance_sensitive_attrs(None, x_test, distances_boundary_test, x_control_test, sensitive_attrs)\n",
    "        p_rule = ut.print_classifier_fairness_stats([test_score], [correlation_dict_test], [cov_dict_test], sensitive_attrs[0])\t\n",
    "        return w, p_rule, test_score\n",
    "\n",
    "\n",
    "    \"\"\" Classify the data while optimizing for accuracy \"\"\"\n",
    "    print\n",
    "    print(\"== Unconstrained (original) classifier ==\")\n",
    "    # all constraint flags are set to 0 since we want to train an unconstrained (original) classifier\n",
    "    apply_fairness_constraints = 0\n",
    "    apply_accuracy_constraint = 0\n",
    "    sep_constraint = 0\n",
    "    w_uncons, p_uncons, acc_uncons = train_test_classifier()\n",
    "    loss_uncons = lf._logistic_loss(w_uncons, x_train, y_train)\n",
    "    print(\"loss of unconstrained model: %f\"%loss_uncons)\n",
    "\n",
    "    \"\"\" Now classify such that we optimize for accuracy while achieving perfect fairness \"\"\"\n",
    "    apply_fairness_constraints = 1 # set this flag to one since we want to optimize accuracy subject to fairness constraints\n",
    "    apply_accuracy_constraint = 0\n",
    "    sep_constraint = 0\n",
    "    \n",
    "    p_f_cons_arr = []\n",
    "    acc_f_cons_arr = []\n",
    "    loss_cons_arr = []\n",
    "    for idx, c in zip(range(len(crange)),crange):\n",
    "        sensitive_attrs_to_cov_thresh = {\"sex\":c}\n",
    "        print(\"== Classifier with fairness constraint == c=%f\"%c)\n",
    "        w_f_cons, p_f_cons, acc_f_cons  = train_test_classifier()\n",
    "        p_f_cons_arr.append(p_f_cons)\n",
    "        acc_f_cons_arr.append(acc_f_cons)\n",
    "        loss_f_cons = lf._logistic_loss(w_f_cons, x_train, y_train)\n",
    "        loss_cons_arr.append(loss_f_cons)\n",
    "        print(\"loss of constrained model with c=%f: %f\"%(c,loss_f_cons))\n",
    "\n",
    "    return p_uncons, acc_uncons, loss_uncons, p_f_cons_arr, acc_f_cons_arr, loss_cons_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 219389,
     "status": "ok",
     "timestamp": 1568158768504,
     "user": {
      "displayName": "Hu Xiao",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCYEuPXFTMSisFgiWhSqUJvzs0MjakNcUO3hyguzQ=s64",
      "userId": "02825967592979012764"
     },
     "user_tz": -120
    },
    "id": "jUP1KD-M3zVj",
    "outputId": "e8c6da8b-5b8c-438f-e99e-a54a4c9fe093"
   },
   "outputs": [],
   "source": [
    "crange = np.linspace(0.4,0,10)\n",
    "p_uncons, acc_uncons, loss_uncons, p_f_cons_arr, acc_f_cons_arr, loss_cons_arr=test_adult_data_max_acc_under_fairness_constraints(crange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1716,
     "status": "ok",
     "timestamp": 1568160447155,
     "user": {
      "displayName": "Hu Xiao",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mCYEuPXFTMSisFgiWhSqUJvzs0MjakNcUO3hyguzQ=s64",
      "userId": "02825967592979012764"
     },
     "user_tz": -120
    },
    "id": "q1_Pi9IH3zV1",
    "outputId": "6a97d074-5e00-463a-9173-411d8153836f"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "p_f_cons_arr=np.array(p_f_cons_arr, dtype=np.float)\n",
    "\n",
    "\n",
    "# plot p-rule vs covariance threshold\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(crange,p_f_cons_arr[::-1],color='magenta')\n",
    "font = {'family' : 'sans-serif',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 10}\n",
    "\n",
    "# plt.legend(['sss'])\n",
    "ax.set(xlabel='Empirical covariance', ylabel='p%-rule', title='Cov. vs. p%-rule')\n",
    "ax.grid(True)\n",
    "plt.xticks([0,0.2,0.4], ('0.4', '0.2', '0'))\n",
    "\n",
    "ax.set_xlim(0.0, 0.4)\n",
    "ax.set_ylim(20, 100)\n",
    "plt.show()\n",
    "fig.savefig('adult_p_rule_cov.png', dpi=600)\n",
    "\n",
    "# plot relative loss vs covariance threshold\n",
    "fig, ax = plt.subplots()\n",
    "loss_cons_arr=np.array(loss_cons_arr, dtype=np.float)\n",
    "relative_loss = loss_cons_arr - loss_uncons\n",
    "relative_loss = relative_loss / relative_loss.max()\n",
    "\n",
    "ax.plot(crange,relative_loss[::-1],color='blue')\n",
    "\n",
    "ax.set(xlabel='Empirical covariance', ylabel='Relative loss', title='Cov. vs. Relative loss')\n",
    "ax.grid(True)\n",
    "plt.xticks([0,0.2,0.4], ('0.4', '0.2', '0'))\n",
    "\n",
    "ax.set_xlim(0.0, 0.4)\n",
    "ax.set_ylim(0, 1)\n",
    "plt.savefig('adult_loss_cov.png', dpi=600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_adult_data_max_fair_accuracy_constraints(gammarange = np.linspace(0,1,11),filepath='./data'):\n",
    "    \"\"\" Load the adult data \"\"\"\n",
    "    X, y, x_control = load_adult_data(filepath,load_data_size=30000) # set the argument to none, or no arguments if you want to test with the whole data -- we are subsampling for performance speedup\n",
    "    ut.compute_p_rule(x_control[\"sex\"], y) # compute the p-rule in the original data\n",
    "\n",
    "    \"\"\" Split the data into train and test \"\"\"\n",
    "    X = ut.add_intercept(X) # add intercept to X before applying the linear classifier\n",
    "    train_fold_size = 0.7\n",
    "    x_train, y_train, x_control_train, x_test, y_test, x_control_test = ut.split_into_train_test(X, y, x_control, train_fold_size)\n",
    "\n",
    "    apply_fairness_constraints = None\n",
    "    apply_accuracy_constraint = None\n",
    "    sep_constraint = None\n",
    "\n",
    "    loss_function = lf._logistic_loss\n",
    "    sensitive_attrs = [\"sex\"]\n",
    "    sensitive_attrs_to_cov_thresh = {}\n",
    "    gamma = None\n",
    "\n",
    "    def train_test_classifier():\n",
    "        w = ut.train_model(x_train, y_train, x_control_train, loss_function, \n",
    "                           apply_fairness_constraints, apply_accuracy_constraint, \n",
    "                           sep_constraint, sensitive_attrs, \n",
    "                           sensitive_attrs_to_cov_thresh, gamma)\n",
    "        train_score, test_score, correct_answers_train, correct_answers_test = ut.check_accuracy(w, x_train, y_train, x_test, y_test, None, None)\n",
    "        distances_boundary_test = (np.dot(x_test, w)).tolist()\n",
    "        all_class_labels_assigned_test = np.sign(distances_boundary_test)\n",
    "        correlation_dict_test = ut.get_correlations(None, None, all_class_labels_assigned_test, x_control_test, sensitive_attrs)\n",
    "        cov_dict_test = ut.print_covariance_sensitive_attrs(None, x_test, distances_boundary_test, x_control_test, sensitive_attrs)\n",
    "        p_rule = ut.print_classifier_fairness_stats([test_score], [correlation_dict_test], [cov_dict_test], sensitive_attrs[0])    \n",
    "        \n",
    "        #\n",
    "        distances_boundary_train = (np.dot(x_train, w)).tolist()\n",
    "        all_class_labels_assigned_train = np.sign(distances_boundary_train)\n",
    "        correlation_dict_train = ut.get_correlations(None, None, all_class_labels_assigned_train, x_control_train, sensitive_attrs)\n",
    "        cov_dict_train = ut.print_covariance_sensitive_attrs(None, x_train, distances_boundary_train, x_control_train, sensitive_attrs)\n",
    "        p_rule_train = ut.print_classifier_fairness_stats([train_score], [correlation_dict_train], [cov_dict_train], sensitive_attrs[0]) \n",
    "        \n",
    "        return w, p_rule, test_score, p_rule_train, train_score\n",
    "\n",
    "\n",
    "    \"\"\" Classify the data while optimizing for accuracy \"\"\"\n",
    "    print\n",
    "    print(\"== Unconstrained (original) classifier ==\")\n",
    "    # all constraint flags are set to 0 since we want to train an unconstrained (original) classifier\n",
    "    apply_fairness_constraints = 0\n",
    "    apply_accuracy_constraint = 0\n",
    "    sep_constraint = 0\n",
    "    w_uncons, p_uncons, acc_uncons,_,_ = train_test_classifier()\n",
    "    loss_uncons = lf._logistic_loss(w_uncons, x_train, y_train)\n",
    "    print(\"loss of unconstrained model: %f\"%loss_uncons)\n",
    "\n",
    "    \"\"\" Classify such that we optimize for fairness subject to a certain loss in accuracy \"\"\"\n",
    "    apply_fairness_constraints = 0 # set this flag to one since we want to optimize accuracy subject to fairness constraints\n",
    "    apply_accuracy_constraint = 1\n",
    "    sep_constraint = 0\n",
    "    \n",
    "    p_a_cons_arr = []\n",
    "    acc_a_cons_arr = []\n",
    "    loss_cons_arr = []\n",
    "    p_a_cons_train_arr = []\n",
    "    acc_a_cons_train_arr = []\n",
    "    for idx, gamma in zip(range(len(gammarange)),gammarange):\n",
    "        print(\"== Classifier with accuracy constraint ==, gamma=%f\"%gamma)\n",
    "        w_a_cons, p_a_cons, acc_a_cons, p_a_cons_train, acc_a_cons_train = train_test_classifier()\n",
    "        print('TRAIN: p-rule %f, accuracy: %f'%(p_a_cons_train,acc_a_cons_train))\n",
    "        print('TEST: p-rule %f, accuracy: %f'%(p_a_cons,acc_a_cons))\n",
    "        p_a_cons_arr.append(p_a_cons)\n",
    "        acc_a_cons_arr.append(acc_a_cons)\n",
    "        p_a_cons_train_arr.append(p_a_cons_train)\n",
    "        acc_a_cons_train_arr.append(acc_a_cons_train)\n",
    "    return p_uncons, acc_uncons, loss_uncons, p_a_cons_arr, acc_a_cons_arr, loss_cons_arr, p_a_cons_train_arr, acc_a_cons_train_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data points: 30000\n",
      "# non-protected examples: 20213\n",
      "# protected examples: 9787\n",
      "Non-protected in positive class: 6352 (31%)\n",
      "Protected in positive class: 1102 (11%)\n",
      "P-rule is: 36%\n",
      "== Unconstrained (original) classifier ==\n",
      "Accuracy: 0.85\n",
      "Protected/non-protected in +ve class: 8% / 26%\n",
      "P-rule achieved: 32%\n",
      "Covariance between sensitive feature and decision from distance boundary : 0.381\n",
      "Accuracy: 0.85\n",
      "Protected/non-protected in +ve class: 8% / 26%\n",
      "P-rule achieved: 32%\n",
      "Covariance between sensitive feature and decision from distance boundary : 0.367\n",
      "loss of unconstrained model: 6840.457504\n",
      "== Classifier with accuracy constraint ==, gamma=0.000000\n",
      "Accuracy: 0.85\n",
      "Protected/non-protected in +ve class: 8% / 26%\n",
      "P-rule achieved: 32%\n",
      "Covariance between sensitive feature and decision from distance boundary : 0.381\n",
      "Accuracy: 0.85\n",
      "Protected/non-protected in +ve class: 8% / 26%\n",
      "P-rule achieved: 32%\n",
      "Covariance between sensitive feature and decision from distance boundary : 0.367\n",
      "TRAIN: p-rule 32.417129, accuracy: 0.848333\n",
      "TEST: p-rule 32.217665, accuracy: 0.847778\n",
      "== Classifier with accuracy constraint ==, gamma=0.100000\n",
      "Accuracy: 0.84\n",
      "Protected/non-protected in +ve class: 13% / 20%\n",
      "P-rule achieved: 63%\n",
      "Covariance between sensitive feature and decision from distance boundary : 0.082\n",
      "Accuracy: 0.84\n",
      "Protected/non-protected in +ve class: 14% / 21%\n",
      "P-rule achieved: 66%\n",
      "Covariance between sensitive feature and decision from distance boundary : 0.073\n",
      "TRAIN: p-rule 65.911655, accuracy: 0.841762\n",
      "TEST: p-rule 62.923234, accuracy: 0.839000\n",
      "== Classifier with accuracy constraint ==, gamma=0.200000\n",
      "Accuracy: 0.82\n",
      "Protected/non-protected in +ve class: 15% / 16%\n",
      "P-rule achieved: 96%\n",
      "Covariance between sensitive feature and decision from distance boundary : 0.003\n",
      "Accuracy: 0.82\n",
      "Protected/non-protected in +ve class: 16% / 16%\n",
      "P-rule achieved: 98%\n",
      "Covariance between sensitive feature and decision from distance boundary : 0.000\n",
      "TRAIN: p-rule 98.316547, accuracy: 0.823238\n",
      "TEST: p-rule 96.336274, accuracy: 0.819667\n",
      "== Classifier with accuracy constraint ==, gamma=0.300000\n",
      "Accuracy: 0.80\n",
      "Protected/non-protected in +ve class: 14% / 13%\n",
      "P-rule achieved: 108%\n",
      "Covariance between sensitive feature and decision from distance boundary : 0.005\n",
      "Accuracy: 0.81\n",
      "Protected/non-protected in +ve class: 14% / 13%\n",
      "P-rule achieved: 106%\n",
      "Covariance between sensitive feature and decision from distance boundary : 0.000\n",
      "TRAIN: p-rule 105.588557, accuracy: 0.808333\n",
      "TEST: p-rule 107.625810, accuracy: 0.804000\n",
      "== Classifier with accuracy constraint ==, gamma=0.400000\n",
      "Accuracy: 0.80\n",
      "Protected/non-protected in +ve class: 20% / 22%\n",
      "P-rule achieved: 90%\n",
      "Covariance between sensitive feature and decision from distance boundary : 0.007\n",
      "Accuracy: 0.80\n",
      "Protected/non-protected in +ve class: 20% / 22%\n",
      "P-rule achieved: 89%\n",
      "Covariance between sensitive feature and decision from distance boundary : 0.000\n",
      "TRAIN: p-rule 89.190344, accuracy: 0.796905\n",
      "TEST: p-rule 90.176807, accuracy: 0.796000\n",
      "== Classifier with accuracy constraint ==, gamma=0.500000\n",
      "Accuracy: 0.79\n",
      "Protected/non-protected in +ve class: 18% / 22%\n",
      "P-rule achieved: 84%\n",
      "Covariance between sensitive feature and decision from distance boundary : 0.007\n",
      "Accuracy: 0.79\n",
      "Protected/non-protected in +ve class: 19% / 22%\n",
      "P-rule achieved: 85%\n",
      "Covariance between sensitive feature and decision from distance boundary : 0.000\n",
      "TRAIN: p-rule 85.189119, accuracy: 0.790762\n",
      "TEST: p-rule 83.673918, accuracy: 0.791444\n",
      "== Classifier with accuracy constraint ==, gamma=0.600000\n",
      "Accuracy: 0.77\n",
      "Protected/non-protected in +ve class: 26% / 27%\n",
      "P-rule achieved: 95%\n",
      "Covariance between sensitive feature and decision from distance boundary : 0.006\n",
      "Accuracy: 0.77\n",
      "Protected/non-protected in +ve class: 26% / 28%\n",
      "P-rule achieved: 93%\n",
      "Covariance between sensitive feature and decision from distance boundary : 0.000\n",
      "TRAIN: p-rule 92.981758, accuracy: 0.772238\n",
      "TEST: p-rule 94.827842, accuracy: 0.771444\n",
      "== Classifier with accuracy constraint ==, gamma=0.700000\n",
      "Accuracy: 0.77\n",
      "Protected/non-protected in +ve class: 22% / 24%\n",
      "P-rule achieved: 93%\n",
      "Covariance between sensitive feature and decision from distance boundary : 0.010\n",
      "Accuracy: 0.77\n",
      "Protected/non-protected in +ve class: 22% / 24%\n",
      "P-rule achieved: 91%\n",
      "Covariance between sensitive feature and decision from distance boundary : 0.000\n",
      "TRAIN: p-rule 90.887204, accuracy: 0.768333\n",
      "TEST: p-rule 92.571371, accuracy: 0.770889\n",
      "== Classifier with accuracy constraint ==, gamma=0.800000\n",
      "Accuracy: 0.77\n",
      "Protected/non-protected in +ve class: 19% / 23%\n",
      "P-rule achieved: 85%\n",
      "Covariance between sensitive feature and decision from distance boundary : 0.011\n",
      "Accuracy: 0.77\n",
      "Protected/non-protected in +ve class: 19% / 23%\n",
      "P-rule achieved: 85%\n",
      "Covariance between sensitive feature and decision from distance boundary : 0.000\n",
      "TRAIN: p-rule 84.595242, accuracy: 0.773667\n",
      "TEST: p-rule 85.365854, accuracy: 0.774333\n",
      "== Classifier with accuracy constraint ==, gamma=0.900000\n",
      "Accuracy: 0.78\n",
      "Protected/non-protected in +ve class: 19% / 22%\n",
      "P-rule achieved: 85%\n",
      "Covariance between sensitive feature and decision from distance boundary : 0.007\n",
      "Accuracy: 0.78\n",
      "Protected/non-protected in +ve class: 18% / 22%\n",
      "P-rule achieved: 84%\n",
      "Covariance between sensitive feature and decision from distance boundary : 0.000\n",
      "TRAIN: p-rule 83.864522, accuracy: 0.777286\n",
      "TEST: p-rule 84.878049, accuracy: 0.778000\n",
      "== Classifier with accuracy constraint ==, gamma=1.000000\n",
      "Accuracy: 0.77\n",
      "Protected/non-protected in +ve class: 16% / 20%\n",
      "P-rule achieved: 84%\n",
      "Covariance between sensitive feature and decision from distance boundary : 0.015\n",
      "Accuracy: 0.76\n",
      "Protected/non-protected in +ve class: 16% / 19%\n",
      "P-rule achieved: 83%\n",
      "Covariance between sensitive feature and decision from distance boundary : 0.000\n",
      "TRAIN: p-rule 83.078116, accuracy: 0.762429\n",
      "TEST: p-rule 83.500717, accuracy: 0.765556\n"
     ]
    }
   ],
   "source": [
    "gammarange = np.linspace(0,1,11)\n",
    "p_uncons, acc_uncons, _, p_a_cons_arr, acc_a_cons_arr, _, p_a_cons_train_arr,acc_a_cons_train_arr=test_adult_data_max_fair_accuracy_constraints(gammarange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc_a_cons_arr=np.array(acc_a_cons_arr, dtype=np.float)\n",
    "p_a_cons_arr=np.array(p_a_cons_arr, dtype=np.float)\n",
    "\n",
    "# plot p-rule vs covariance threshold\n",
    "fig, ax1 = plt.subplots()\n",
    "color = 'tab:orange'\n",
    "ax1.set_xlabel(' loss factor')\n",
    "ax1.set_ylabel('Acc', color=color)\n",
    "ax1.semilogx(gammarange, acc_a_cons_arr, color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('p%-rule', color=color)  # we already handled the x-label with ax1\n",
    "ax2.semilogx(gammarange, p_a_cons_arr, color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "plt.title('Acc and p%-rule')\n",
    "plt.grid(True)\n",
    "plt.savefig('adult_loss_acc_p_rule.png', dpi=600)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do some tests\n",
    "def compare_uncons_cons():\n",
    "    \"\"\" Load the adult data \"\"\"\n",
    "    X, y, x_control = load_adult_data('./') # set the argument to none, or no arguments if you want to test with the whole data -- we are subsampling for performance speedup\n",
    "    ut.compute_p_rule(x_control[\"sex\"], y) # compute the p-rule in the original data\n",
    "\n",
    "    \"\"\" Split the data into train and test \"\"\"\n",
    "    X = ut.add_intercept(X) # add intercept to X before applying the linear classifier\n",
    "    train_fold_size = 0.7\n",
    "    x_train, y_train, x_control_train, x_test, y_test, x_control_test = ut.split_into_train_test(X, y, x_control, train_fold_size)\n",
    "\n",
    "    apply_fairness_constraints = None\n",
    "    apply_accuracy_constraint = None\n",
    "    sep_constraint = None\n",
    "\n",
    "    loss_function = lf._logistic_loss\n",
    "    sensitive_attrs = [\"sex\"]\n",
    "    sensitive_attrs_to_cov_thresh = {}\n",
    "    gamma = None\n",
    "\n",
    "    def train_test_classifier():\n",
    "        w = ut.train_model(x_train, y_train, x_control_train, loss_function, \n",
    "                           apply_fairness_constraints, apply_accuracy_constraint, \n",
    "                           sep_constraint, sensitive_attrs, \n",
    "                           sensitive_attrs_to_cov_thresh, gamma)\n",
    "        y_pred = np.sign(np.dot(x_test, w))\n",
    "        return w, y_pred\n",
    "\n",
    "\n",
    "    \"\"\" Classify the data while optimizing for accuracy \"\"\"\n",
    "    print\n",
    "    print(\"== Unconstrained (original) classifier ==\")\n",
    "    # all constraint flags are set to 0 since we want to train an unconstrained (original) classifier\n",
    "    apply_fairness_constraints = 0\n",
    "    apply_accuracy_constraint = 0\n",
    "    sep_constraint = 0\n",
    "    w_uncons, y_pred_uncons = train_test_classifier()\n",
    "\n",
    "    \"\"\" Now classify such that we optimize for accuracy while achieving perfect fairness \"\"\"\n",
    "    apply_fairness_constraints = 1 # set this flag to one since we want to optimize accuracy subject to fairness constraints\n",
    "    apply_accuracy_constraint = 0\n",
    "    sep_constraint = 0\n",
    "    c = 0.1\n",
    "    sensitive_attrs_to_cov_thresh = {\"sex\":c}\n",
    "    print(\"== Classifier with fairness constraint == c=%f\"%c)\n",
    "    w_f_cons, y_pred_f_cons  = train_test_classifier()\n",
    "        \n",
    "    \"\"\" Classify such that we optimize for fairness subject to a certain loss in accuracy \"\"\"\n",
    "    apply_fairness_constraints = 0 # set this flag to one since we want to optimize accuracy subject to fairness constraints\n",
    "    apply_accuracy_constraint = 1\n",
    "    sep_constraint = 0\n",
    "    gamma = 0.5\n",
    "    print(\"== Classifier with accuracy constraint ==, gamma=%f\"%gamma)\n",
    "    w_a_cons, y_pred_a_cons = train_test_classifier()\n",
    "    \n",
    "    return y_test, y_pred_uncons, y_pred_f_cons, y_pred_a_cons\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled1.ipynb",
   "provenance": [
    {
     "file_id": "1O8cDF-c_ZWXsUj4eY4cPQ52ab2Mb-otE",
     "timestamp": 1568147805185
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
